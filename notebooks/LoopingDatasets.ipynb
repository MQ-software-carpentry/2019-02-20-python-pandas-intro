{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a `for` loop to process files given a list of their names.\n",
    "\n",
    "*   A filename is just a character string.\n",
    "*   And lists can contain character strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['../data/gapminder_gdp_africa.csv', '../data/gapminder_gdp_asia.csv']\n",
    "\n",
    "for filename in file_list:\n",
    "    data = pd.read_csv(filename, index_col='country')\n",
    "    print(filename, data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `glob.glob` to find sets of files whose names match a pattern.\n",
    "\n",
    "*   In Unix, the term \"globbing\" means \"matching a set of files with a pattern\".\n",
    "*   The most common patterns are:\n",
    "    *   `*` meaning \"match zero or more characters\"\n",
    "    *   `?` meaning \"match exactly one character\"\n",
    "*   Python contains the `glob` library to provide pattern matching functionality\n",
    "*   The `glob` library contains a function also called `glob` to match file patterns\n",
    "*   E.g., `glob.glob('*.txt')` matches all files in the current directory \n",
    "    whose names end with `.txt`.\n",
    "*   Result is a (possibly empty) list of character strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "print('all csv files in data directory:', glob.glob('../data/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any debug files?\n",
    "print('all PDB files:', glob.glob('*.pdb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `glob` and `for` to process batches of files.\n",
    "\n",
    "*   Helps a lot if the files are named and stored systematically and consistently\n",
    "    so that simple patterns will find the right data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob('../data/gapminder_*.csv'):\n",
    "    data = pd.read_csv(filename)\n",
    "    min_52 = data['gdpPercap_1952'].min()\n",
    "    print(filename, min_52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   This includes all data, as well as per-region data.\n",
    "*   Use a more specific pattern in the exercises to exclude the whole data set.\n",
    "*   But note that the minimum of the entire data set is also the minimum of one of the data sets,\n",
    "    which is a nice check on correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data sets using `pd.concat`\n",
    "\n",
    "We can [concatenate](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) (i.e. join) data sets together\n",
    "using the aptly named `pd.concat` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('../data/gapminder_*.csv')\n",
    "\n",
    "data_list = list()\n",
    "for fn in file_list:\n",
    "    data0 = pd.read_csv(fn)\n",
    "    data_list.append(data0)\n",
    "    \n",
    "data = pd.concat(data_list, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Efficient concat\n",
    "\n",
    "> There is a much cleaner way to use `pd.concat` and list comprehensions. Try that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up dataframe using concat and a list comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Determining Matches\n",
    ">\n",
    "> Which of these files is *not* matched by the expression `glob.glob('data/*as*.csv')`?\n",
    ">\n",
    "> 1. `data/gapminder_gdp_africa.csv`\n",
    "> 2. `data/gapminder_gdp_americas.csv`\n",
    "> 3. `data/gapminder_gdp_asia.csv`\n",
    "> 4. 1 and 2 are not matched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Minimum File Size\n",
    ">\n",
    "> Modify this program so that it prints the number of records in\n",
    "> the file that has the fewest records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas\n",
    "fewest = ____\n",
    "for filename in glob.glob('../data/gapminder_*.csv'):\n",
    "    dataframe = pandas.____(filename)\n",
    "    fewest = min(____, dataframe.shape[0])\n",
    "print('smallest file has', fewest, 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Comparing Data\n",
    ">\n",
    "> Write a program that reads in the regional data sets\n",
    "> and plots the average GDP per capita for each region over time\n",
    "> in a single chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas \n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for filename in glob.glob('../data/gapminder_gdp*.csv'):\n",
    "    dataframe = pandas.read_csv(filename)\n",
    "    # extract region from the filename, expected to be in the format '../data/gapminder_gdp_<region>.csv'\n",
    "    region = filename.rpartition('_')[2][:-4] \n",
    "    dataframe.mean().plot(ax=ax, label=region, rot=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to?\n",
    "\n",
    "[Check-in](02-Checkin.ipynb) on putting some data sets together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- \"How can I process many data sets with a single command?\"\n",
    "\n",
    "### Objectives:\n",
    "- \"Be able to read and write globbing expressions that match sets of files.\"\n",
    "- \"Use glob to create lists of files.\"\n",
    "- \"Write for loops to perform operations on files given their names in a list.\"\n",
    "\n",
    "### Keypoints:\n",
    "- \"Use a `for` loop to process files given a list of their names.\"\n",
    "- \"Use `glob.glob` to find sets of files whose names match a pattern.\"\n",
    "- \"Use `glob` and `for` to process batches of files.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Software Carpentry\n",
    "* [Looping Over Data Sets](http://swcarpentry.github.io/python-novice-gapminder/13-looping-data-sets/)\n",
    "\n",
    "### Other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
